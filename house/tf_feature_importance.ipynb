{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzq/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.preprocessing as pre\n",
    "import xgboost as xgb\n",
    "#pip install xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#pip install sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/zzq/kaggle/house/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/home/zzq/kaggle/house/test.csv\")\n",
    "test_miss=test_df.isnull().sum(axis=0).reset_index()\n",
    "test_miss.columns=['name','count']\n",
    "test_miss=test_miss.ix[test_miss['count']>0]\n",
    "miss_name=test_miss['name'].values\n",
    "print miss_name.shape\n",
    "test_name=['id','timestamp']\n",
    "for i in range(48):\n",
    "    test_name.append(str(miss_name[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将有空值的提取出来\n",
    "missing_df = train_df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.ix[missing_df['missing_count']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print type(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51,)\n"
     ]
    }
   ],
   "source": [
    "# print missing_df\n",
    "name=missing_df['column_name'].values\n",
    "name_list=[]\n",
    "print name.shape\n",
    "for i in range(51):\n",
    "    name_list.append(str(name[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "name_list.append('id')\n",
    "name_list.append('timestamp')\n",
    "print len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7662, 238)\n<type 'str'>\nstr\n"
     ]
    }
   ],
   "source": [
    "test_feature=test_df.drop(name_list,axis=1)\n",
    "test_feature_nd=test_feature.as_matrix()\n",
    "print test_feature_nd.shape\n",
    "print type(test_feature_nd[1][1])\n",
    "if type(test_feature_nd[1][1])==type('str'):\n",
    "    print 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0\n 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n 1.0 1.0 1.0 1.0]\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "max_=test_feature_nd.max(axis=0)\n",
    "min_=test_feature_nd.min(axis=0)\n",
    "print max_\n",
    "for i in range(238):\n",
    "    if type(max_[i])==type('demo'):\n",
    "        max_[i]=1.0\n",
    "    if type(min_[i])==type('demo'):\n",
    "        min_[i]=0.0\n",
    "    if max_[i]==min_[i]:\n",
    "        max_[i]=1.0\n",
    "        \n",
    "for i in range(7662):\n",
    "    for j in range(238):\n",
    "        if type(test_feature_nd[i][j])==type('Occ'):\n",
    "            test_feature_nd[i][j]=0.0\n",
    "        else:\n",
    "            if test_feature_nd[i][j]==max_[j]:\n",
    "                test_feature_nd[i][j]=1.0\n",
    "            else:\n",
    "                test_feature_nd[i][j]=(float(test_feature_nd[i][j])-float(min_[j]))/(max_[j]-min_[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zzq/kaggle/house/test_file/feature_238.csv','w') as test:\n",
    "    np.savetxt(test,test_feature_nd,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "name_list.append('id')\n",
    "name_list.append('timestamp')\n",
    "name_list.append('price_doc')\n",
    "feature=train_df.drop(name_list, axis=1)\n",
    "print type(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=30471, step=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471, 238)\n"
     ]
    }
   ],
   "source": [
    "print feature.index\n",
    "print feature.shape\n",
    "feature_nd=feature.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n(30471, 238)\n"
     ]
    }
   ],
   "source": [
    "print type(feature_nd)\n",
    "print feature_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#价钱值\n",
    "#将奇值去掉\n",
    "ulimit = np.percentile(train_df.price_doc.values, 99.5)\n",
    "llimit = np.percentile(train_df.price_doc.values, 0.5)\n",
    "train_df['price_doc'].ix[train_df['price_doc']>ulimit] = ulimit\n",
    "train_df['price_doc'].ix[train_df['price_doc']<llimit] = llimit\n",
    "train_y = train_df['price_doc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471,)\n<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print train_y.shape\n",
    "print type(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471,)\n"
     ]
    }
   ],
   "source": [
    "b=np.reshape(train_y,30471)\n",
    "print b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850000.0\n6000000.0\n5700000.0\n13100000.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_label=[]\n",
    "for i in range(30471):\n",
    "    price_label.append(int(b[i]/1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5850000.   6000000.   5700000. ...,   6970959.  13500000.   5600000.]\n"
     ]
    }
   ],
   "source": [
    "print train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850000.0\n"
     ]
    }
   ],
   "source": [
    "print train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price=np.asarray(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d8dd1a9d384f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# print np.shape(price)\n",
    "# print price[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32105366.6\n990000.0\n"
     ]
    }
   ],
   "source": [
    "print train_y.max()\n",
    "print train_y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'int'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-00ccfcdd88a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "price=[]\n",
    "price=train_y\n",
    "print type(price)\n",
    "print price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'tolist'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-10e250c01cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'tolist'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# train_y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'int'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3ca2f3407cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_y_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print type(train_y)\n",
    "train_y_list=list(train_y)\n",
    "print type(train_y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object has no attribute '__getitem__'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0ae99961bc6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30471\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object has no attribute '__getitem__'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "label=[]\n",
    "for i in range(30471):\n",
    "    label.append(train_y[i]/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what I need is feature_nd and price_label\n",
    "import tensorflow as tf\n",
    "def add_layer(input,input_size,output_size,action_fun=None):\n",
    "    weights=tf.Variable(tf.random_normal([input_size,output_size]))\n",
    "    biases=tf.Variable(tf.zeros([1,output_size])+0.1)\n",
    "    ans=tf.matmul(input,weights)+biases\n",
    "    if action_fun is None:\n",
    "        output=ans\n",
    "    else:\n",
    "        output=action_fun(ans)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=tf.placeholder(tf.float32,[None,1])\n",
    "ys=tf.placeholder(tf.float32,[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471, 238)\n"
     ]
    }
   ],
   "source": [
    "print feature_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer1=add_layer(xs,1,1000,action_fun=tf.nn.relu)#there must be 1\n",
    "hidden_layer2=add_layer(hidden_layer1,1000,1000,action_fun=tf.nn.relu)\n",
    "hidden_layer3=add_layer(hidden_layer2,1000,200,action_fun=tf.nn.relu)\n",
    "prediction=add_layer(hidden_layer3,200,1,action_fun=None)\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices = [1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "max_=feature_nd.max(axis=0)\n",
    "min_=feature_nd.min(axis=0)\n",
    "for i in range(30471):\n",
    "    for j in range(238):\n",
    "        if type(feature_nd[i][j])==type('str'):\n",
    "            feature_nd[i][j]=0.0\n",
    "        else:\n",
    "            if feature_nd[i][j]==max_[j]:\n",
    "                feature_nd[i][j]=1.0\n",
    "            else:\n",
    "                feature_nd[i][j]=(float(feature_nd[i][j])-float(min_[j]))/(float(max_[j])-float(min_[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isfile('/home/zzq/kaggle/house/feartures/feature_238.csv'):\n",
    "    os.remove('/home/zzq/kaggle/house/feartures/feature_238.csv')\n",
    "\n",
    "for i in range(30471):\n",
    "    out=file('/home/zzq/kaggle/house/feartures/feature_238.csv','a+')\n",
    "    xian=''\n",
    "    for j in range(237):\n",
    "        xian+=('%.6f'%feature_nd[i][j]+',')\n",
    "    xian+=('%.6f'%feature_nd[i][237]+'\\n')\n",
    "    out.write(xian)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0514824186876\n"
     ]
    }
   ],
   "source": [
    "print feature_nd[3][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n<type 'float'>\n"
     ]
    }
   ],
   "source": [
    "print type(feature_nd)\n",
    "print type(feature_nd[4][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines=open('/home/zzq/kaggle/house/label_cls20').readlines()\n",
    "y_label=[]\n",
    "for i in range(0,len(all_lines)):\n",
    "    lin=all_lines[i].strip('\\n')\n",
    "    data=int(lin)\n",
    "    if data>=20:\n",
    "        data=20\n",
    "    y_label.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what I need is feature_nd and y_label\n",
    "writer = tf.python_io.TFRecordWriter('/home/zzq/kaggle/house/feartures/feature_238.tfrecord')\n",
    "feature_raw = feature_nd.tostring()\n",
    "example = tf.train.Example(\n",
    "        features = tf.train.Features(\n",
    "            feature = {'label':tf.train.Feature(int64_list = tf.train.Int64List(value = y)),\n",
    "                       'feature':tf.train.Feature(bytes_list = tf.train.BytesList(value = [feature_raw]))}))\n",
    "serialized = example.SerializeToString()\n",
    "writer.write(serialized)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30471\n"
     ]
    }
   ],
   "source": [
    "print len(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取队列的数据\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        # Defaults are not specified since both keys are required.\n",
    "        features={\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'feature': tf.FixedLenFeature([], tf.string)\n",
    "        })\n",
    "    label=features['label']\n",
    "    feature=features['feature']\n",
    "    feature_raw=tf.decode_raw(feature,tf.float64)\n",
    "    return feature_raw,label\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['/home/zzq/kaggle/house/feartures/feature_238.tfrecord'], num_epochs=10)\n",
    "feature, label = read_and_decode(filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot=np.zeros((30471,20))\n",
    "for i in range(30471):\n",
    "    one_hot[i][y_label[i]-1]=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 500\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 238 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 20 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "# with tf.device('/gpu:0'):\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(init)\n",
    "        avg_cost = 0.\n",
    "        # with tf.device('/gpu:0'):\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: feature_nd,\n",
    "                                                          y: one_hot})\n",
    "            # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "    # Training cycle\n",
    "    \n",
    "        # \n",
    "        # total_batch = int(30471/batch_size)\n",
    "        # # Loop over all batches\n",
    "        # for i in range(total_batch):\n",
    "        # \n",
    "        #     # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        #     \n",
    "        # # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zzq/kaggle/house/feartures/one_hot.csv','w') as my_file:\n",
    "    np.savetxt(my_file,one_hot,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}